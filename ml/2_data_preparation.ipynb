{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-24T13:34:17.674935Z",
     "start_time": "2025-01-24T13:34:17.512878Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow.dataset as ds\n",
    "import pvlib\n",
    "\n",
    "# disable warnings from pandas\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c7174decc89e19a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   PV Serial Number Location  Latitude  Longitude  From date    To date  \\\n0          84071567   Lisbon    38.728     -9.138 2019-01-01 2022-12-31   \n1          84071569   Lisbon    38.833     -9.191 2019-01-01 2022-12-31   \n2          84071568  Setubal    38.577     -8.872 2019-01-01 2022-12-31   \n3          84071570   Lisbon    38.725     -9.120 2019-01-01 2022-12-31   \n4          84071566     Faro    37.031     -7.893 2019-01-01 2022-12-31   \n5          62030198    Braga    41.493     -8.496 2019-01-01 2022-12-31   \n6          62032213   Lisbon    38.701     -9.236 2019-01-01 2022-12-31   \n7          73060645   Tavira    37.131     -7.645 2019-01-01 2022-12-31   \n8          73061935    Loule    37.131     -8.038 2019-01-01 2022-12-31   \n\n   Installed Power (kWp)  Connection Power (kWn)  \n0                  46.00                    40.0  \n1                  16.32                    15.0  \n2                  23.52                    20.0  \n3                  30.00                    27.0  \n4                   7.00                     6.6  \n5                  64.93                    60.0  \n6                  22.54                    20.0  \n7                  46.00                    40.0  \n8                  46.25                    40.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PV Serial Number</th>\n      <th>Location</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>From date</th>\n      <th>To date</th>\n      <th>Installed Power (kWp)</th>\n      <th>Connection Power (kWn)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>84071567</td>\n      <td>Lisbon</td>\n      <td>38.728</td>\n      <td>-9.138</td>\n      <td>2019-01-01</td>\n      <td>2022-12-31</td>\n      <td>46.00</td>\n      <td>40.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>84071569</td>\n      <td>Lisbon</td>\n      <td>38.833</td>\n      <td>-9.191</td>\n      <td>2019-01-01</td>\n      <td>2022-12-31</td>\n      <td>16.32</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84071568</td>\n      <td>Setubal</td>\n      <td>38.577</td>\n      <td>-8.872</td>\n      <td>2019-01-01</td>\n      <td>2022-12-31</td>\n      <td>23.52</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84071570</td>\n      <td>Lisbon</td>\n      <td>38.725</td>\n      <td>-9.120</td>\n      <td>2019-01-01</td>\n      <td>2022-12-31</td>\n      <td>30.00</td>\n      <td>27.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84071566</td>\n      <td>Faro</td>\n      <td>37.031</td>\n      <td>-7.893</td>\n      <td>2019-01-01</td>\n      <td>2022-12-31</td>\n      <td>7.00</td>\n      <td>6.6</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>62030198</td>\n      <td>Braga</td>\n      <td>41.493</td>\n      <td>-8.496</td>\n      <td>2019-01-01</td>\n      <td>2022-12-31</td>\n      <td>64.93</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>62032213</td>\n      <td>Lisbon</td>\n      <td>38.701</td>\n      <td>-9.236</td>\n      <td>2019-01-01</td>\n      <td>2022-12-31</td>\n      <td>22.54</td>\n      <td>20.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>73060645</td>\n      <td>Tavira</td>\n      <td>37.131</td>\n      <td>-7.645</td>\n      <td>2019-01-01</td>\n      <td>2022-12-31</td>\n      <td>46.00</td>\n      <td>40.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>73061935</td>\n      <td>Loule</td>\n      <td>37.131</td>\n      <td>-8.038</td>\n      <td>2019-01-01</td>\n      <td>2022-12-31</td>\n      <td>46.25</td>\n      <td>40.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portugal_metadata = pd.read_excel('data/PortugalPhotovoltaicDataset/pv_plants_metadata.xlsx')\n",
    "portugal_metadata"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T13:34:18.625667Z",
     "start_time": "2025-01-24T13:34:18.540112Z"
    }
   },
   "id": "38ba484873f7bb63",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   ss_id  latitude_rounded  longitude_rounded    llsoacd  orientation  tilt  \\\n0   2405             53.53              -1.63  E01007430        180.0  35.0   \n1   2406             54.88              -1.38  E01008780        315.0  30.0   \n2   2407             54.88              -1.38  E01008780        225.0  30.0   \n3   2408             54.88              -1.38  E01008780        225.0  30.0   \n4   2409             54.88              -1.38  E01008780        225.0  30.0   \n\n    kwp operational_at  \n0  3.36     2010-11-18  \n1  1.89     2010-12-03  \n2  1.89     2010-12-03  \n3  1.89     2010-12-03  \n4  1.89     2010-12-03  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ss_id</th>\n      <th>latitude_rounded</th>\n      <th>longitude_rounded</th>\n      <th>llsoacd</th>\n      <th>orientation</th>\n      <th>tilt</th>\n      <th>kwp</th>\n      <th>operational_at</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2405</td>\n      <td>53.53</td>\n      <td>-1.63</td>\n      <td>E01007430</td>\n      <td>180.0</td>\n      <td>35.0</td>\n      <td>3.36</td>\n      <td>2010-11-18</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2406</td>\n      <td>54.88</td>\n      <td>-1.38</td>\n      <td>E01008780</td>\n      <td>315.0</td>\n      <td>30.0</td>\n      <td>1.89</td>\n      <td>2010-12-03</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2407</td>\n      <td>54.88</td>\n      <td>-1.38</td>\n      <td>E01008780</td>\n      <td>225.0</td>\n      <td>30.0</td>\n      <td>1.89</td>\n      <td>2010-12-03</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2408</td>\n      <td>54.88</td>\n      <td>-1.38</td>\n      <td>E01008780</td>\n      <td>225.0</td>\n      <td>30.0</td>\n      <td>1.89</td>\n      <td>2010-12-03</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2409</td>\n      <td>54.88</td>\n      <td>-1.38</td>\n      <td>E01008780</td>\n      <td>225.0</td>\n      <td>30.0</td>\n      <td>1.89</td>\n      <td>2010-12-03</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uk_open_climate_fix_metadata = pd.read_csv(\"data/UKOpenClimateFix/uk_pv_metadata.csv\")\n",
    "uk_open_climate_fix_metadata.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T16:19:32.661966Z",
     "start_time": "2025-01-14T16:19:32.610110Z"
    }
   },
   "id": "f16ceb7d64ba3724",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                 Date  Produced Energy (kWh)  Specific Energy (kWh/kWp)  \\\n0 2019-01-01 00:00:00                    0.0                        0.0   \n1 2019-01-01 01:00:00                    0.0                        0.0   \n2 2019-01-01 02:00:00                    0.0                        0.0   \n3 2019-01-01 03:00:00                    0.0                        0.0   \n4 2019-01-01 04:00:00                    0.0                        0.0   \n\n  CO2 Avoided (tons)    serial      name  \n0                     84071567  Lisbon_1  \n1                     84071567  Lisbon_1  \n2                     84071567  Lisbon_1  \n3                     84071567  Lisbon_1  \n4                     84071567  Lisbon_1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Produced Energy (kWh)</th>\n      <th>Specific Energy (kWh/kWp)</th>\n      <th>CO2 Avoided (tons)</th>\n      <th>serial</th>\n      <th>name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019-01-01 00:00:00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td></td>\n      <td>84071567</td>\n      <td>Lisbon_1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019-01-01 01:00:00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td></td>\n      <td>84071567</td>\n      <td>Lisbon_1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019-01-01 02:00:00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td></td>\n      <td>84071567</td>\n      <td>Lisbon_1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019-01-01 03:00:00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td></td>\n      <td>84071567</td>\n      <td>Lisbon_1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019-01-01 04:00:00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td></td>\n      <td>84071567</td>\n      <td>Lisbon_1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load portugal dataset\n",
    "file_path = 'data/PortugalPhotovoltaicDataset/pv_plants_datasets.xlsx'\n",
    "\n",
    "# define the correspondence table between sheet names and real names\n",
    "correspondence = {\n",
    "    'Lisbon_1': ['84071567'],\n",
    "    'Lisbon_2': ['84071569'],\n",
    "    'Lisbon_3': ['84071570'],\n",
    "    'Lisbon_4': ['62032213'], \n",
    "    'Setubal': ['84071568'],\n",
    "    'Faro': ['84071566'],\n",
    "    'Braga': ['62030198'],\n",
    "    'Tavira': ['73060645'],\n",
    "    'Loule': ['73061935']\n",
    "}\n",
    "\n",
    "data_frames = []\n",
    "for real_name, sheet_names in correspondence.items():\n",
    "    for sheet_name in sheet_names:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        df['serial'] = sheet_name\n",
    "        df['name'] = real_name\n",
    "        data_frames.append(df)\n",
    "\n",
    "portugal_df = pd.concat(data_frames, ignore_index=True)\n",
    "portugal_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-24T13:34:29.301188Z",
     "start_time": "2025-01-24T13:34:22.457260Z"
    }
   },
   "id": "84fdf6fbcd2ffad7",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Open Parquet dataset\n",
    "dataset = ds.dataset(\"data/UKOpenClimateFix/uk_pv_30_minute_data.parquet\", format=\"parquet\")\n",
    "\n",
    "# Create a filter for the data\n",
    "filtered_table = dataset.to_table(filter=(ds.field('ss_id').isin([3062, 3800, 7115, 7497, 8712, 9992, 24865, 24964, 26754, 24962, 19064, 23524, 17446, 10618, 24696])))\n",
    "\n",
    "# Convert to pandas DataFrame (if needed)\n",
    "uk_open_climate_fix_df = filtered_table.to_pandas()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T15:53:20.323810Z",
     "start_time": "2025-01-14T15:52:52.756712Z"
    }
   },
   "id": "d1b7039c4371e677",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "650959de0eff3fcd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Portugal dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b34c2f0d326b3801"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_fixed_azimuth_tilt(latitude, longitude, start_date, end_date):\n",
    "    results = []\n",
    "\n",
    "    location = pvlib.location.Location(latitude=latitude, longitude=longitude)\n",
    "    times = pd.date_range(start=start_date, end=end_date, freq='h')\n",
    "\n",
    "    clearsky = location.get_clearsky(times)\n",
    "    solar_position = location.get_solarposition(times)\n",
    "\n",
    "    tilt_angles = np.arange(0, 90, 5)  # Tilt from 0 to 90 degrees in 5-degree increments\n",
    "    azimuth_angles = np.arange(0, 180, 10)  # Azimuth from 0 to 180 degrees in 10-degree increments\n",
    "\n",
    "    # Loop through tilt and azimuth combinations\n",
    "    for tilt in tilt_angles:\n",
    "        for azimuth in azimuth_angles:\n",
    "            # Calculate total irradiance on the panel\n",
    "            irradiance = pvlib.irradiance.get_total_irradiance(\n",
    "                surface_tilt=tilt,\n",
    "                surface_azimuth=azimuth,\n",
    "                solar_zenith=solar_position['apparent_zenith'],\n",
    "                solar_azimuth=solar_position['azimuth'],\n",
    "                dni=clearsky['dni'],\n",
    "                ghi=clearsky['ghi'],\n",
    "                dhi=clearsky['dhi'],\n",
    "                model='isotropic'\n",
    "            )\n",
    "            # Sum global irradiance over the year\n",
    "            total_irradiance = irradiance['poa_global'].sum()\n",
    "            results.append({'tilt': tilt, 'azimuth': azimuth, 'irradiance': total_irradiance})\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    optimal_row = results_df.loc[results_df['irradiance'].idxmax()]\n",
    "    optimal_tilt = optimal_row['tilt']\n",
    "    optimal_azimuth = optimal_row['azimuth']\n",
    "\n",
    "    return optimal_tilt, optimal_azimuth"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T13:38:15.041049Z",
     "start_time": "2025-01-12T13:38:15.020086Z"
    }
   },
   "id": "ae881462a7b72451",
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make data in the same format"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a3e760a062692bc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Ensure dates are in datetime format and strip time\n",
    "portugal_metadata[\"From date\"] = pd.to_datetime(portugal_metadata[\"From date\"]).dt.strftime('%Y-%m-%d')\n",
    "portugal_metadata[\"To date\"] = pd.to_datetime(portugal_metadata[\"To date\"]).dt.strftime('%Y-%m-%d')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T13:38:15.067719Z",
     "start_time": "2025-01-12T13:38:15.042200Z"
    }
   },
   "id": "42a44deb77c7cd3c",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "   PV Serial Number Location  Latitude  Longitude   From date     To date  \\\n0          84071567   Lisbon    38.728     -9.138  2019-01-01  2022-12-31   \n1          84071569   Lisbon    38.833     -9.191  2019-01-01  2022-12-31   \n2          84071568  Setubal    38.577     -8.872  2019-01-01  2022-12-31   \n3          84071570   Lisbon    38.725     -9.120  2019-01-01  2022-12-31   \n4          84071566     Faro    37.031     -7.893  2019-01-01  2022-12-31   \n5          62030198    Braga    41.493     -8.496  2019-01-01  2022-12-31   \n6          62032213   Lisbon    38.701     -9.236  2019-01-01  2022-12-31   \n7          73060645   Tavira    37.131     -7.645  2019-01-01  2022-12-31   \n8          73061935    Loule    37.131     -8.038  2019-01-01  2022-12-31   \n\n   Installed Power (kWp)  Connection Power (kWn)  optimal_tilt  \\\n0                  46.00                    40.0          35.0   \n1                  16.32                    15.0          35.0   \n2                  23.52                    20.0          35.0   \n3                  30.00                    27.0          35.0   \n4                   7.00                     6.6          35.0   \n5                  64.93                    60.0          40.0   \n6                  22.54                    20.0          35.0   \n7                  46.00                    40.0          35.0   \n8                  46.25                    40.0          35.0   \n\n   optimal_azimuth  \n0            170.0  \n1            170.0  \n2            170.0  \n3            170.0  \n4            170.0  \n5            170.0  \n6            170.0  \n7            170.0  \n8            170.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PV Serial Number</th>\n      <th>Location</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>From date</th>\n      <th>To date</th>\n      <th>Installed Power (kWp)</th>\n      <th>Connection Power (kWn)</th>\n      <th>optimal_tilt</th>\n      <th>optimal_azimuth</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>84071567</td>\n      <td>Lisbon</td>\n      <td>38.728</td>\n      <td>-9.138</td>\n      <td>2019-01-01</td>\n      <td>2022-12-31</td>\n      <td>46.00</td>\n      <td>40.0</td>\n      <td>35.0</td>\n      <td>170.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>84071569</td>\n      <td>Lisbon</td>\n      <td>38.833</td>\n      <td>-9.191</td>\n      <td>2019-01-01</td>\n      <td>2022-12-31</td>\n      <td>16.32</td>\n      <td>15.0</td>\n      <td>35.0</td>\n      <td>170.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84071568</td>\n      <td>Setubal</td>\n      <td>38.577</td>\n      <td>-8.872</td>\n      <td>2019-01-01</td>\n      <td>2022-12-31</td>\n      <td>23.52</td>\n      <td>20.0</td>\n      <td>35.0</td>\n      <td>170.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84071570</td>\n      <td>Lisbon</td>\n      <td>38.725</td>\n      <td>-9.120</td>\n      <td>2019-01-01</td>\n      <td>2022-12-31</td>\n      <td>30.00</td>\n      <td>27.0</td>\n      <td>35.0</td>\n      <td>170.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84071566</td>\n      <td>Faro</td>\n      <td>37.031</td>\n      <td>-7.893</td>\n      <td>2019-01-01</td>\n      <td>2022-12-31</td>\n      <td>7.00</td>\n      <td>6.6</td>\n      <td>35.0</td>\n      <td>170.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>62030198</td>\n      <td>Braga</td>\n      <td>41.493</td>\n      <td>-8.496</td>\n      <td>2019-01-01</td>\n      <td>2022-12-31</td>\n      <td>64.93</td>\n      <td>60.0</td>\n      <td>40.0</td>\n      <td>170.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>62032213</td>\n      <td>Lisbon</td>\n      <td>38.701</td>\n      <td>-9.236</td>\n      <td>2019-01-01</td>\n      <td>2022-12-31</td>\n      <td>22.54</td>\n      <td>20.0</td>\n      <td>35.0</td>\n      <td>170.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>73060645</td>\n      <td>Tavira</td>\n      <td>37.131</td>\n      <td>-7.645</td>\n      <td>2019-01-01</td>\n      <td>2022-12-31</td>\n      <td>46.00</td>\n      <td>40.0</td>\n      <td>35.0</td>\n      <td>170.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>73061935</td>\n      <td>Loule</td>\n      <td>37.131</td>\n      <td>-8.038</td>\n      <td>2019-01-01</td>\n      <td>2022-12-31</td>\n      <td>46.25</td>\n      <td>40.0</td>\n      <td>35.0</td>\n      <td>170.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since in portugal dataset no information about tilt and azimuth, we will calculate the optimal tilt and azimuth and assume that they are fixed\n",
    "\n",
    "for _, solar_plant in portugal_metadata.iterrows():\n",
    "    optimal_tilt, optimal_azimuth = calculate_fixed_azimuth_tilt(\n",
    "        latitude=solar_plant[\"Latitude\"],\n",
    "        longitude=solar_plant[\"Longitude\"],\n",
    "        start_date=solar_plant[\"From date\"],\n",
    "        end_date=solar_plant[\"To date\"]\n",
    "    )\n",
    "    portugal_metadata.loc[_, 'optimal_tilt'] = optimal_tilt\n",
    "    portugal_metadata.loc[_, 'optimal_azimuth'] = optimal_azimuth\n",
    "    \n",
    "portugal_metadata"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T13:38:21.699300Z",
     "start_time": "2025-01-12T13:38:15.068648Z"
    }
   },
   "id": "eaeeb34d3710d3bc",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "     serial      name            datetime  produced energy\n0  84071567  Lisbon_1 2019-01-01 00:00:00              0.0\n1  84071567  Lisbon_1 2019-01-01 01:00:00              0.0\n2  84071567  Lisbon_1 2019-01-01 02:00:00              0.0\n3  84071567  Lisbon_1 2019-01-01 03:00:00              0.0\n4  84071567  Lisbon_1 2019-01-01 04:00:00              0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>serial</th>\n      <th>name</th>\n      <th>datetime</th>\n      <th>produced energy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>84071567</td>\n      <td>Lisbon_1</td>\n      <td>2019-01-01 00:00:00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>84071567</td>\n      <td>Lisbon_1</td>\n      <td>2019-01-01 01:00:00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84071567</td>\n      <td>Lisbon_1</td>\n      <td>2019-01-01 02:00:00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84071567</td>\n      <td>Lisbon_1</td>\n      <td>2019-01-01 03:00:00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84071567</td>\n      <td>Lisbon_1</td>\n      <td>2019-01-01 04:00:00</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portugal_df = portugal_df[[\"serial\", \"name\", \"Date\", \"Produced Energy (kWh)\"]]\n",
    "portugal_df.rename(\n",
    "    columns={\n",
    "        \"Date\": \"datetime\",\n",
    "        \"Produced Energy (kWh)\": \"produced energy\"\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "portugal_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T13:38:21.721300Z",
     "start_time": "2025-01-12T13:38:21.699917Z"
    }
   },
   "id": "2b6c9050f51d3bd7",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Merge portugal_df with portugal_metadata based on the \"serial\" column\n",
    "portugal_df['serial'] = portugal_df['serial'].astype(str)\n",
    "portugal_metadata['PV Serial Number'] = portugal_metadata['PV Serial Number'].astype(str)\n",
    "\n",
    "portugal_df = portugal_df.merge(\n",
    "    portugal_metadata[[\"PV Serial Number\", \"Installed Power (kWp)\"]],  # Columns to bring\n",
    "    left_on=\"serial\",  # Column in portugal_df\n",
    "    right_on=\"PV Serial Number\",  # Column in portugal_metadata\n",
    "    how=\"left\"  # Type of join\n",
    ")\n",
    "\n",
    "portugal_df.rename(\n",
    "    columns={\n",
    "        \"Installed Power (kWp)\": \"kwp\"\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "portugal_df['produced energy'] = portugal_df['produced energy'].round(2)  # Round to 2 decimal places\n",
    "portugal_df.drop(columns=[\"PV Serial Number\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T13:38:21.770893Z",
     "start_time": "2025-01-12T13:38:21.721882Z"
    }
   },
   "id": "46b6a5c556dc9933",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Extract date and time features\n",
    "portugal_df['year'] = portugal_df['datetime'].dt.year\n",
    "portugal_df['month'] = portugal_df['datetime'].dt.month\n",
    "portugal_df['day'] = portugal_df['datetime'].dt.day\n",
    "portugal_df['hour'] = portugal_df['datetime'].dt.hour\n",
    "portugal_df['minute'] = portugal_df['datetime'].dt.minute\n",
    "\n",
    "portugal_df.drop(columns=[\"datetime\"], inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T13:38:21.802217Z",
     "start_time": "2025-01-12T13:38:21.771457Z"
    }
   },
   "id": "dde07dfd8aaafcac",
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "source": [
    "# UK dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "502a9f97d15f4786"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before cleanup:\n",
      "generation_wh    4\n",
      "datetime         0\n",
      "ss_id            0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after cleanup:\n",
      "generation_wh    0\n",
      "datetime         0\n",
      "ss_id            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "print(\"Missing values before cleanup:\")\n",
    "print(uk_open_climate_fix_df.isna().sum())\n",
    "\n",
    "# Drop NaN values and reset index\n",
    "uk_open_climate_fix_df = uk_open_climate_fix_df.dropna().reset_index(drop=True)\n",
    "\n",
    "print(\"\\nMissing values after cleanup:\")\n",
    "print(uk_open_climate_fix_df.isna().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T15:53:30.284465Z",
     "start_time": "2025-01-14T15:53:30.221226Z"
    }
   },
   "id": "461e4e9b46e9886d",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def group_complete_hours_by_plant(df, datetime_col, energy_col, plant_id_col, plant_id):\n",
    "    \"\"\"\n",
    "    Groups data by complete hours for a specific PV plant where both 30-minute intervals are present.\n",
    "\n",
    "    Parameters:\n",
    "    df : pd.DataFrame - The input DataFrame.\n",
    "    datetime_col : str - The name of the datetime column.\n",
    "    energy_col : str - The name of the energy production column.\n",
    "    plant_id_col : str - The column name for the power plant ID.\n",
    "    plant_id : str or int - The ID of the specific power plant to process.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame - Data grouped by hour with only complete records for the selected plant.\n",
    "    \"\"\"\n",
    "    # Filter the data for the specific plant\n",
    "    plant_data = df[df[plant_id_col] == plant_id].copy()\n",
    "\n",
    "    initial_size = plant_data.shape\n",
    "\n",
    "    # Ensure datetime column is in datetime format\n",
    "    plant_data[datetime_col] = pd.to_datetime(plant_data[datetime_col])\n",
    "\n",
    "    # Extract hour and minute from the timestamp for grouping\n",
    "    plant_data['hour'] = plant_data[datetime_col].dt.floor('h')\n",
    "    plant_data['minute'] = plant_data[datetime_col].dt.minute\n",
    "\n",
    "    # Count the number of records for each hour\n",
    "    hour_counts = plant_data.groupby('hour')[datetime_col].count().reset_index(name='count')\n",
    "\n",
    "    # Identify incomplete hours (count != 2)\n",
    "    incomplete_hours = hour_counts[hour_counts['count'] != 2]\n",
    "    num_incomplete_pairs = incomplete_hours.shape[0]\n",
    "\n",
    "    # Keep only hours with exactly 2 records (both 30-minute intervals)\n",
    "    complete_hours = hour_counts[hour_counts['count'] == 2]['hour']\n",
    "\n",
    "    # Filter the plant data to only include complete hours\n",
    "    complete_plant_data = plant_data[plant_data['hour'].isin(complete_hours)].copy()\n",
    "\n",
    "    # Group by hour and aggregate energy production\n",
    "    grouped_df = complete_plant_data.groupby('hour')[energy_col].sum().reset_index()\n",
    "    grouped_df.rename(columns={'hour': datetime_col}, inplace=True)\n",
    "\n",
    "    print(f\"Initial size: {initial_size}\")\n",
    "    print(f\"Grouped size: {grouped_df.shape}\")\n",
    "    print(f\"Number of incomplete hour pairs (missing :00 or :30): {num_incomplete_pairs}\")\n",
    "\n",
    "    return grouped_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T15:38:10.068818Z",
     "start_time": "2025-01-14T15:38:10.060022Z"
    }
   },
   "id": "81fc3bc102ed7efa",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial size: (66000, 3)\n",
      "Grouped size: (33000, 2)\n",
      "Number of incomplete hour pairs (missing :00 or :30): 0\n",
      "Initial size: (72672, 3)\n",
      "Grouped size: (36336, 2)\n",
      "Number of incomplete hour pairs (missing :00 or :30): 0\n",
      "Initial size: (81168, 3)\n",
      "Grouped size: (40584, 2)\n",
      "Number of incomplete hour pairs (missing :00 or :30): 0\n",
      "Initial size: (74640, 3)\n",
      "Grouped size: (37320, 2)\n",
      "Number of incomplete hour pairs (missing :00 or :30): 0\n",
      "Initial size: (75168, 3)\n",
      "Grouped size: (37584, 2)\n",
      "Number of incomplete hour pairs (missing :00 or :30): 0\n",
      "Initial size: (77760, 3)\n",
      "Grouped size: (38880, 2)\n",
      "Number of incomplete hour pairs (missing :00 or :30): 0\n",
      "Initial size: (128732, 3)\n",
      "Grouped size: (64366, 2)\n",
      "Number of incomplete hour pairs (missing :00 or :30): 0\n",
      "Initial size: (134112, 3)\n",
      "Grouped size: (67056, 2)\n",
      "Number of incomplete hour pairs (missing :00 or :30): 0\n",
      "Initial size: (128880, 3)\n",
      "Grouped size: (64440, 2)\n",
      "Number of incomplete hour pairs (missing :00 or :30): 0\n",
      "Initial size: (139392, 3)\n",
      "Grouped size: (69696, 2)\n",
      "Number of incomplete hour pairs (missing :00 or :30): 0\n",
      "Initial size: (102192, 3)\n",
      "Grouped size: (51096, 2)\n",
      "Number of incomplete hour pairs (missing :00 or :30): 0\n",
      "Initial size: (167664, 3)\n",
      "Grouped size: (83832, 2)\n",
      "Number of incomplete hour pairs (missing :00 or :30): 0\n",
      "Initial size: (164880, 3)\n",
      "Grouped size: (82440, 2)\n",
      "Number of incomplete hour pairs (missing :00 or :30): 0\n",
      "Initial size: (120240, 3)\n",
      "Grouped size: (60120, 2)\n",
      "Number of incomplete hour pairs (missing :00 or :30): 0\n",
      "Initial size: (72768, 3)\n",
      "Grouped size: (36384, 2)\n",
      "Number of incomplete hour pairs (missing :00 or :30): 0\n"
     ]
    }
   ],
   "source": [
    "uk_open_climate_fix_df_temp = []\n",
    "\n",
    "for ss_id in set(uk_open_climate_fix_df[\"ss_id\"]):\n",
    "    pv_grouped = group_complete_hours_by_plant(uk_open_climate_fix_df, \"datetime\", \"generation_wh\", \"ss_id\", ss_id)\n",
    "    pv_grouped[\"ss_id\"] = ss_id\n",
    "    uk_open_climate_fix_df_temp.append(pv_grouped)\n",
    "    \n",
    "uk_open_climate_fix_df_selected_hourly = pd.concat(uk_open_climate_fix_df_temp)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T15:53:38.329913Z",
     "start_time": "2025-01-14T15:53:37.621247Z"
    }
   },
   "id": "e623f059971dc77c",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Format to the same as portugal dataset\n",
    "Convert Wh to kWh"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e8bced9661cfde"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'generation_wh'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/University/Final Project/ML/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'generation_wh'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m uk_open_climate_fix_df_selected_hourly[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mproduced energy\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43muk_open_climate_fix_df_selected_hourly\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mgeneration_wh\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m1000\u001B[39m \u001B[38;5;66;03m# Convert Wh to kWh\u001B[39;00m\n\u001B[1;32m      2\u001B[0m uk_open_climate_fix_df_selected_hourly[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mproduced energy\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m uk_open_climate_fix_df_selected_hourly[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mproduced energy\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mround(\u001B[38;5;241m2\u001B[39m) \u001B[38;5;66;03m# Round to 2 decimal places\u001B[39;00m\n\u001B[1;32m      3\u001B[0m uk_open_climate_fix_df_selected_hourly\u001B[38;5;241m.\u001B[39mdrop(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgeneration_wh\u001B[39m\u001B[38;5;124m\"\u001B[39m], inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/University/Final Project/ML/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/University/Final Project/ML/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3810\u001B[0m     ):\n\u001B[1;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'generation_wh'"
     ]
    }
   ],
   "source": [
    "uk_open_climate_fix_df_selected_hourly['produced energy'] = uk_open_climate_fix_df_selected_hourly['generation_wh'] / 1000 # Convert Wh to kWh\n",
    "uk_open_climate_fix_df_selected_hourly['produced energy'] = uk_open_climate_fix_df_selected_hourly['produced energy'].round(2) # Round to 2 decimal places\n",
    "uk_open_climate_fix_df_selected_hourly.drop(columns=[\"generation_wh\"], inplace=True)\n",
    "\n",
    "uk_open_climate_fix_df_selected_hourly['ss_id'] = uk_open_climate_fix_df_selected_hourly['ss_id'].astype(str)\n",
    "uk_open_climate_fix_metadata['ss_id'] = uk_open_climate_fix_metadata['ss_id'].astype(str)\n",
    "\n",
    "uk_open_climate_fix_df_selected_hourly = uk_open_climate_fix_df_selected_hourly.merge(\n",
    "    uk_open_climate_fix_metadata[[\"ss_id\", \"kwp\"]],  # Columns to bring\n",
    "    left_on=\"ss_id\",  # Column in portugal_df\n",
    "    right_on=\"ss_id\",  # Column in portugal_metadata\n",
    "    how=\"left\"  # Type of join\n",
    ")\n",
    "\n",
    "# align the column names with the portugal dataset\n",
    "uk_open_climate_fix_df_selected_hourly.rename(\n",
    "    columns={\n",
    "        \"ss_id\": \"serial\"\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T16:19:46.352689Z",
     "start_time": "2025-01-14T16:19:45.955772Z"
    }
   },
   "id": "db8df5d13c6fc669",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Extract date and time features\n",
    "uk_open_climate_fix_df_selected_hourly['year'] = uk_open_climate_fix_df_selected_hourly['datetime'].dt.year\n",
    "uk_open_climate_fix_df_selected_hourly['month'] = uk_open_climate_fix_df_selected_hourly['datetime'].dt.month\n",
    "uk_open_climate_fix_df_selected_hourly['day'] = uk_open_climate_fix_df_selected_hourly['datetime'].dt.day\n",
    "uk_open_climate_fix_df_selected_hourly['hour'] = uk_open_climate_fix_df_selected_hourly['datetime'].dt.hour\n",
    "uk_open_climate_fix_df_selected_hourly['minute'] = uk_open_climate_fix_df_selected_hourly['datetime'].dt.minute\n",
    "\n",
    "uk_open_climate_fix_df_selected_hourly.drop(columns=[\"datetime\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T15:53:48.090724Z",
     "start_time": "2025-01-14T15:53:48.016701Z"
    }
   },
   "id": "3bff2f6885224a18",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Save datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd989bf31e82e022"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "portugal_metadata.to_csv(\"data/PortugalPhotovoltaicDataset/photovoltaic_dataset_metadata.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T13:38:22.451484Z",
     "start_time": "2025-01-12T13:38:22.395460Z"
    }
   },
   "id": "a818c77e938fcd40",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "uk_open_climate_fix_metadata.to_csv(\"data/UKOpenClimateFix/uk_open_climate_fixed_metadata.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T15:38:34.890963Z",
     "start_time": "2025-01-14T15:38:34.802263Z"
    }
   },
   "id": "f93be67dd3e27cd7",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "portugal_df.to_csv(\"data/PortugalPhotovoltaicDataset/photovoltaic_dataset_raw.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T13:38:22.868967Z",
     "start_time": "2025-01-12T13:38:22.452399Z"
    }
   },
   "id": "30c703a3e21050b2",
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "uk_open_climate_fix_df_selected_hourly.to_csv(\"data/UKOpenClimateFix/uk_open_climate_hourly_dataset_raw.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-14T15:53:54.379913Z",
     "start_time": "2025-01-14T15:53:53.464587Z"
    }
   },
   "id": "b81881c01f781248",
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
